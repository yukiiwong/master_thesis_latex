\chapter{总结与展望}
\label{chp:version_license}

\section{总结}

在本文中，我们提出了一种基于DRL的新型JTMDTC模型，用于在动态多模式交通网络中最大化个体的出行效用。与主要依赖随机效用理论描述出行行为的传统DCM不同，所提出的方法是由一种学习机制驱动的，通过在多个日子里不断与复杂的交通环境互动，智能体不断改进决策逻辑。这个过程被视为一个顺序决策问题，问题的解决方案是（接近）最优的JTMDTC，帮助个体实现尽可能高的出行效用。然而，这样的决策并不一定是从行为角度出发的。相反，它更像是移动即服务中的指导或建议，个体向系统发出出行请求，系统处理所有请求，为个体的出行选择提供建议。

为了在这种情境下有效应用DRL，构建了一个问题特定的MDP，以表征多日JTMDTC。然后开发了一个定制的DQN作为解决方案，适用于高维和/或连续空间问题。为了使该方法能够处理许多具有出行决策请求的个体，将聚类方法集成到建模框架中，以获得代表性的个体来训练智能体，从而实现优雅且计算效率高的方法。我们基于中国苏州实际网络中的多模式微观模拟进行了大量数值实验，以证明所提出方法的有效性。通过与其他几种模型进行比较，我们表明所提出的方法能够在复杂交通环境中为不同个体做出（接近）最优的JTMDTC决策，同时具有更高的出行效用，并且该方法对不同模型参数的变化具有鲁棒性。

本研究提出的整体建模框架实际上受到了理性人类决策机制的启发，即从经验中学习。这是构建MDP和DRL模型的基础。尽管奖励函数仍然受随机效用理论驱动，但可以设计不同的函数来考虑可能的人类行为特征，如出行惯性。换句话说，所提出的方法具有更灵活的建模结构，可以用于开发具有异质出行目标的模型。最终目标或许是为个体在JTMDTC上提供一些个性化的指导或建议。

\section{展望}

在这项研究中，我们提出了一种DRL方法，为在高峰时段（早上7点至9点）出行的个体提供更好的出行选择。该方法旨在在考虑不同出行方式的同时，最大程度地减少用户的出行时间和成本。我们的研究结果表明，该方法在提供准确、高效的出行建议方面是有效的。这种方法的一个关键优势是其灵活性，因为奖励函数可以根据不同用户或情况的特定需求和要求进行调整。然而，需要注意的是，当前模型是为单个旅行者设计的，并没有考虑多个旅行者对交通系统的潜在影响。这是一个未来研究的重要领域，模型可以扩展到多智能体框架。

本研究的另一个局限性是它不是一个实时推荐系统，需要一天的出行需求数据才能为第二天提供出行建议。因此，未来的研究可以通过整合实时数据来开发实时推荐系统。

在未来的研究中，还有一些问题有待进一步探讨。其中一个问题是如何将个体的行为和社会人口特征纳入建模框架，因为这些已知会影响出行选择。另一个问题是如何将换乘作为一种附加的交通方式（例如，停车换乘）纳入考虑，因为目前只考虑了公共交通之间的换乘。最后，探讨如何考虑和建模个体在出行选择方面的动态互动和合作将是值得的。这可以更好地利用交通网络资源，提高整个系统的效率。