\chapter{针对多智能体的模式与出发时间选择方法}
\label{chp:bib}

\section{基于聚类的深度强化学习方法}

在前一节中，我们详细阐述了DQN算法作为解决JTMDTC问题的基本解决方案。然而，如何将该算法推广到解决具有大量个体的相同问题仍然是一个开放性问题。我们先前已经讨论过，存储所有个体的经验进行训练是计算上不明智且低效的，而随机选择一个或几个个体是不够的且不可靠的。因此，我们提出了一种优雅而有效的方法来获取代表性个体，以进行高效的模型训练，即基于个体的出行特征进行聚类。对于处于同一聚类中的个体，我们认为它们的出行特征相似。因此，它们中的每一个都可以被视为该聚类的代表，其经验可以代表其余个体来训练DQN。通过这种方式，我们不仅避免了部署与个体数量相同数量的代理，而且还有效地利用代表性个体的经验进行充分的模型训练。事实上，采用所提出的方法可以有效地解决具有许多个体的JTMDTC问题，而不会在决策制定中牺牲太多的最优性。我们将在结果中提供支持性证据。



\subsection{DBSCAN聚类方法}
DBSCAN（Density-Based Spatial Clustering of Applications with Noise）是一种基于密度的聚类算法，旨在识别高密度区域，并将它们作为簇的核心。DBSCAN不需要假设簇的数量，因此是一种非参数方法。它可以自适应地调整簇的大小和形状，并在存在噪声的情况下保持较好的性能。

DBSCAN的核心思想是将数据点分为三类：核心点、边界点和噪声点。核心点是一个密度可达的点集合，即它周围的密度大于等于指定的阈值。边界点是一个密度可达的点，但其周围的密度小于指定的阈值。噪声点则是不属于任何簇的点，它们周围的密度也小于指定的阈值。

除了DBSCAN算法，还有其他一些聚类算法，例如$k$-means和层次聚类。$k$-means算法是一种常用的聚类算法，它通过将数据集划分为$k$个簇来进行聚类。它的核心思想是将数据点分配到距离其最近的质心（簇的中心），并将质心更新为簇中所有点的平均值。然后，重复这个过程直到质心不再变化或达到预定的最大迭代次数。

层次聚类是一种自下而上的聚类方法，它通过递归地将最相似的数据点组合成更大的簇，最终形成一个完整的聚类树。层次聚类可以是聚合的（自底向上）或分裂的（自顶向下）。在聚合层次聚类中，每个数据点开始时都是一个单独的簇，然后将最相似的簇合并在一起，直到所有数据点都被分配到一个簇中。在分裂层次聚类中，开始时将所有数据点都分配到一个大簇中，然后逐步将其分裂成较小的簇，直到达到预定的聚类数目。

尽管$k$-means和层次聚类算法也可以用于代表性个体的选择，但它们对噪声点的处理方式不如DBSCAN算法，可能会将噪声点误分类为一个簇或将它们分配到多个簇中。此外，DBSCAN算法可以自动确定簇的数量，并且不需要提前指定$k$或层次聚类的高度。

在本研究中，我们选择了DBSCAN算法作为代表性个体的选择算法，因为它能够很好地处理数据噪声和密度不均匀的情况，并且不需要提前指定簇的数量。通过聚类选择代表性个体，我们可以大大减少强化学习算法中状态和动作空间的规模，并提高训练效率。


\subsection{聚类参数的选择}

\subsection{深度强化学习模型的改进}
将定制的DQN与个体聚类和获取代表性的过程相结合，得到了解决具有许多个体的JTMDTC问题的最终集成算法。要训练的代理数量等于代表或群集的数量。这些代理与它们各自的存储池同时进行训练。一旦充分训练，它们就可以联合使用，为不同的个体做出出行选择决策，无需重新进行聚类。也就是说，选择获得最高奖励的代理所采取的行动来实施。

通过使用基于深度强化学习的仿真平台解决JTMDTC问题，我们的设计目标是提供一个高效，精确且可扩展的仿真工具，以便研究人员和政策制定者能够定量地评估出行模式和出行时间选择的不同策略。我们提出的集成算法通过聚类个体并获取代表性个体来训练代理，从而有效地减少了计算成本并提高了模型训练效率。这种方法不仅可以应用于JTMDTC问题，还可以应用于其他基于个体决策的问题，具有广泛的应用前景。

\section{模型的验证}

\subsection{与传统方法的对比}

\subsection{模型参数的灵敏性分析}