\chapter{针对多智能体的模式与出发时间选择方法}
\label{chp:bib}

\section{基于聚类的深度强化学习方法}

在前一节中，我们详细阐述了DQN算法作为解决JTMDTC问题的基本解决方案。然而，如何将该算法推广到解决具有大量个体的相同问题仍然是一个开放性问题。我们先前已经讨论过，存储所有个体的经验进行训练是计算上不明智且低效的，而随机选择一个或几个个体是不够的且不可靠的。因此，我们提出了一种优雅而有效的方法来获取代表性个体，以进行高效的模型训练，即基于个体的出行特征进行聚类。对于处于同一聚类中的个体，我们认为它们的出行特征相似。因此，它们中的每一个都可以被视为该聚类的代表，其经验可以代表其余个体来训练DQN。通过这种方式，我们不仅避免了部署与个体数量相同数量的代理，而且还有效地利用代表性个体的经验进行充分的模型训练。事实上，采用所提出的方法可以有效地解决具有许多个体的JTMDTC问题，而不会在决策制定中牺牲太多的最优性。我们将在结果中提供支持性证据。

为了获取代表性个体，我们采用了一种广泛使用的聚类算法，称为具有噪声的基于密度的空间聚类（DBSCAN）\citep{ester1996density}。它是一种非参数方法，无需假设或指定数据分布。DBSCAN的核心是首先识别高密度样本，然后逐渐将那些相似的样本连接成更大的聚类。在聚类时，考虑了两个出行特征作为输入，即出行距离和公共交通的可达性（见方法论）。它们共同提供了个体面临的决策环境的总体图像。

聚类个体和获取代表性个体的整体工作流程在算法\ref{DBSCAN}中呈现。这些代表性个体同时在相同的环境中进行仿真，而不是以单独的方式进行仿真，他们的经验被存储到各自的存储池中进行模型训练。请注意，从每个个体群集中等概率地选择一个代表，不同的组合不会导致显著的性能变化。这将在结果中得到证明。

将定制的DQN与个体聚类和获取代表性的过程相结合，得到了解决具有许多个体的JTMDTC问题的最终集成算法。要训练的代理数量等于代表或群集的数量。这些代理与它们各自的存储池同时进行训练。一旦充分训练，它们就可以联合使用，为不同的个体做出出行选择决策，无需重新进行聚类。也就是说，选择获得最高奖励的代理所采取的行动来实施。

通过使用基于深度强化学习的仿真平台解决JTMDTC问题，我们的设计目标是提供一个高效，精确且可扩展的仿真工具，以便研究人员和政策制定者能够定量地评估出行模式和出行时间选择的不同策略。我们提出的集成算法通过聚类个体并获取代表性个体来训练代理，从而有效地减少了计算成本并提高了模型训练效率。这种方法不仅可以应用于JTMDTC问题，还可以应用于其他基于个体决策的问题，具有广泛的应用前景。

\subsection{DBSCAN聚类方法}


\subsection{聚类参数的选择}

\subsection{深度强化学习模型的改进}


\section{模型的验证}

\subsection{与传统方法的对比}

\subsection{模型参数的灵敏性分析}