%% ----------------------------------------------------------------------------
%%                              Chinese Abstract
%% ----------------------------------------------------------------------------
\begin{abstract}{模式选择,时间选择,深度强化学习,多模式交通,微观交通仿真}
随着现代社会对出行效率和体验要求的提高，交通问题变得日益突出。传统的交通管理方法已经难以应对日益增长的交通需求和不断变化的交通状况，因此如何更好地优化出行者的出行决策，提高个体出行效用成为当前交通领域的重要研究方向之一。基于深度强化学习的出行选择模型可以灵活地调整个体的决策策略，提高出行效用，并具有更高的适应能力。本文旨在提出一种基于深度强化学习的出行模式和时间选择模型，以解决多模式交通网络中的出行决策问题。

首先介绍了深度强化学习的相关知识。依照智能体动作的选取方式将强化学习方法分类为基于价值、基于策略和价值策略相结合的三类方法。接着，重点讨论神经网络在强化学习中的应用、常见的激活函数和损失函数，以及针对深度强化学习的优化方法。并对主流的三种深度强化学习算法(深度Q网络、近端策略优化和深度确定性策略优化）进行了对比，最终选择了深度Q网络的方法作为研究出行模式和时间选择的主要方法。之后选择SUMO作为仿真平台。并完成本文实验所需场景的选择与搭建、路网的编辑与生成、出行模式的设计和流量的生成。设计并构建本文的仿真实验场景，为之后验证本文研究方法。

其次，使用深度强化学习方法刻画出行者的出行选择活动。建立问题特定的马尔可夫决策过程来描述多天的出行模式与时间选择问题场景，并设计相应的深度Q网络作为求解方法，包括神经网络的设计，超参数以及损失函数优化。为了使该模型适用于多个具有出行决策请求的个体，将聚类方法与深度强化学习集成以获取代表性个体以训练智能体，从而保证计算效率与适用性。

最后，在中国苏州的实际城市路网中，基于多模式微观交通仿真进行了大量数值实验。通过损失、奖励以及动作等实验结果，证明所提出的方法的有效性。模型在测试数据集上的结果表明，相较于传统的深度Q网络方法，该模型具有较强的泛化能力与可迁移性。在模拟出行者的对环境部分信息感知决策实验中，本文的方法均比其他替代方法的平均奖励值高，验证了模型具有描述出行者行为活动的可解释性。在灵敏性分析中，对智能体数量的变化和训练个体群组的选择两个模型参数进行测试，验证了不同的模型参数在变化时仍具有可靠性与平稳性。

\end{abstract}

%% ----------------------------------------------------------------------------
%%                              English Abstract
%% ----------------------------------------------------------------------------
\begin{englishabstract}{mode choice, departure time choice, deep reinforcement learning, multimodal transportation, microscopic traffic simulation}
With the increasing demand for travel efficiency and experience in modern society, transportation issues have become increasingly prominent. Traditional transportation management methods are no longer able to cope with the growing transportation demand and constantly changing traffic conditions. Therefore, how to better optimize the travel decisions of individuals and improve individual travel utility has become an important research direction in the field of transportation. Travel selection models based on deep reinforcement learning can flexibly adjust individual decision-making strategies, improve travel utility, and have higher adaptability. This paper aims to propose a travel mode and time selection model based on deep reinforcement learning to solve the travel decision-making problem in a multimodal transportation network.

First, relevant knowledge of deep reinforcement learning is introduced. Reinforcement learning methods are classified into three types based on the selection method of intelligent agent actions: value-based, policy-based, and value-policy hybrid. Then, the application of neural networks in reinforcement learning, common activation functions and loss functions, and optimization methods for deep reinforcement learning are discussed. The mainstream deep reinforcement learning algorithms (Deep Q-Network, Proximal Policy Optimization, and Deep Deterministic Policy Gradient) are compared, and the Deep Q-Network method is ultimately selected as the main method for researching travel mode and time selection. SUMO is selected as the simulation platform. The selection and construction of the experimental scenarios, the editing and generation of road networks, the design of travel modes, and the generation of traffic flow are completed. The simulation experiment scene of this paper is designed and constructed to verify the research method of this paper.

Second, the travel selection activities of travelers are characterized using deep reinforcement learning methods. A problem-specific Markov decision process is established to describe the multi-day travel mode and time selection problem scenario and design the corresponding deep Q-network as the solution method, including neural network design, hyperparameters, and loss function optimization. In order to make the model applicable to multiple individuals with travel decision requests, clustering methods are integrated with deep reinforcement learning to obtain representative individuals to train the intelligent agent, thereby ensuring computational efficiency and applicability.

Finally, a large number of numerical experiments were conducted based on multimodal micro-traffic simulation in the actual urban road network in Suzhou, China. The effectiveness of the proposed method was demonstrated through experimental results such as loss, reward, and action. The results on the test dataset show that compared with the traditional Deep Q-Network method, the model has strong generalization and transferability. In the experiment of simulating the decision-making behavior of travelers with partial information perception of the environment, the average reward value of the proposed method was higher than that of other alternative methods, verifying the interpretability of the model to describe traveler behavior activities. Sensitivity analysis was conducted by testing two model parameters, the number of intelligent agents and the selection of training individual groups, which verified the reliability and stability of different model parameters when they changed.
\end{englishabstract}
