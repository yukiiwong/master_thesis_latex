%% ----------------------------------------------------------------------------
%%                              Chinese Abstract
%% ----------------------------------------------------------------------------
\begin{abstract}{模式选择,时间选择,深度强化学习,多模式交通,微观交通仿真}
随着现代社会对出行效率和体验要求的提高，交通问题变得日益突出。传统的交通管理方法已经难以应对日益增长的交通需求和不断变化的交通状况，因此如何更好地优化交通流动，提高个体出行效用成为当前交通领域的重要研究方向之一。基于强化学习的出行选择模型可以灵活地调整个体的决策策略，提高出行效用，并具有更高的适应能力。本文旨在提出一种基于深度强化学习的出行模式和时间选择模型，以解决动态多模式交通网络中的出行决策问题。

首先介绍了深度强化学习的相关知识。依照智能体动作的选取方式将强化学习方法分类为基于价值、基于策略和价值策略相结合的三类方法。接着重点讨论神经网络在强化学习中的应用、常见的激活函数和损失函数，以及针对深度强化学习的优化方法。并对主流的三种深度强化学习算法进行了对比，选择了深度Q网络的方法作为研究出行模式和时间选择的主要方法。接着，分析了不同仿真平台的优缺点，选择SUMO作为仿真平台。并完成本文实验所需场景的选择与搭建、路网的编辑与生成、出行模式的设计和流量的生成。设计并构建本文的仿真实验场景，为之后验证本文研究方法，以支持论文的主要结论。

其次，本文将每个出行者视为具有学习能力的智能体，并建立问题特定的马尔可夫决策过程来描述多天的出行模式与时间选择问题场景。并设计相应的深度Q网络作为解决方案，包括神经网络的设计，超参数以及损失函数优化。为了使该方法适用于许多具有出行决策请求的个体，将聚类方法与深度强化学习集成以获取代表性个体以训练智能体，从而实现了保证计算效率与适用性的方法。

最后，在中国苏州的实际城市路网中，基于多模式微观交通仿真进行了大量数值实验。通过损失、奖励以及动作等实验结果，证明所提出的方法的有效性。模型在测试数据集上的结果表明，相较于传统的深度Q网络方法，该模型具有较强的泛化能力。在模拟出行者的对环境部分信息感知决策实验中，本文的方法均比其他替代方法的平均奖励值高，验证模型的可解释性。在灵敏性分析中，对智能体数量的变化和训练个体群组的选择两个模型参数进行测试，验证不同的模型参数变化具有鲁棒性。

\end{abstract}

%% ----------------------------------------------------------------------------
%%                              English Abstract
%% ----------------------------------------------------------------------------
\begin{englishabstract}{mode choice, departure time choice, deep reinforcement learning, multimodal transportation, microscopic traffic simulation}
With the increasing demand for travel efficiency and experience in modern society, transportation issues have become increasingly prominent. Traditional traffic management methods are unable to cope with the growing traffic demand and constantly changing traffic conditions. Therefore, how to better optimize traffic flow and improve individual travel utility has become an important research direction in the field of transportation. A travel mode and time selection model based on deep reinforcement learning is proposed in this paper to solve the travel decision-making problem in a dynamic multi-modal transportation network.

Firstly, the relevant knowledge of deep reinforcement learning is introduced. Reinforcement learning methods are classified into three categories based on the selection of agent actions: value-based, policy-based, and a combination of value and policy. The application of neural networks, common activation functions and loss functions, and optimization methods for deep reinforcement learning are discussed. The three mainstream deep reinforcement learning algorithms are compared, and the deep Q network method is selected as the main method for studying travel modes and time selection. Then, the advantages and disadvantages of different simulation platforms are analyzed, and SUMO is chosen as the simulation platform. The selection and construction of the simulation experiment scene, editing and generation of road networks, design of travel modes, and generation of traffic flow are completed. The simulation experiment scene is designed and constructed to verify the research method and support the main conclusions of the paper.

Secondly, this paper regards each traveler as an intelligent agent with learning ability, and establishes a problem-specific Markov decision process to describe the multi-day travel mode and time selection problem. Corresponding deep Q networks are designed as the solution, including neural network design, hyperparameters, and loss function optimization. In order to make this method applicable to many individuals with travel decision requests, clustering methods are integrated with deep reinforcement learning to obtain representative individuals to train the agents, thus achieving a method that ensures computational efficiency and applicability.

Finally, extensive numerical experiments are conducted in the actual urban road network in Suzhou, China, based on multi-modal microscopic traffic simulation. Through experimental results such as loss, reward, and action, the effectiveness of the proposed method is demonstrated. The results on the test dataset show that compared with the traditional deep Q network method, the proposed model has stronger generalization ability. In the experiment of simulating the decision-making of travelers' partial information perception in the environment, the method proposed in this paper has higher average reward values than other alternative methods, validating the interpretability of the model. Sensitivity analysis tests the variation of two model parameters, the number of intelligent agents and the selection of trained individual groups, and verifies the robustness of different model parameter changes.
\end{englishabstract}
